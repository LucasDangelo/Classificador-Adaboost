{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6c5c47",
   "metadata": {},
   "source": [
    "# Classificador Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e4558",
   "metadata": {},
   "source": [
    "Nos últimos anos, os algoritmos de reforço ganharam enorme popularidade nas competições de kaggle. Os vencedores dessas competições usam algoritmos de reforço para obter alto desempenho. Algoritmos de reforço como AdaBoost, Gradient Boosting e XGBoost são algoritmos de aprendizado de máquina amplamente usados. Neste kernel, discutiremos o algoritmo AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c947d91",
   "metadata": {},
   "source": [
    " ## Descrevendo AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287df66",
   "metadata": {},
   "source": [
    "O Adaboost pertence aos métodos de aprendizado conjunto e imita o famoso principio da **\"Sabedoria das Multidões\"** ou seja modelos que individualmente apresentam desempenho ruins, porém quando combinados podem formar um modelo forte.\n",
    "\n",
    "Um estudo do [MIT](https://news.mit.edu/2021/crowd-source-fact-checking-0901) publicado em 2021 descreve como as multidões são capazes de identificar as notícias falsas. Sem qualquer conhecimento prévio ou veracidade dos fatos, os indivíduos geralmente acham difícil identficar notícias falsas de maniera confiável. No entanto, com base em nossa experiência, geralmente somos capazes de fornecer pelo menos uma tendência ou um apontamento, que normalmente funciona melhor do que a adivinhação aleatória. Se quisermos saber a veracidade de uma determinada manchete, podemos simplesmente perguntar a 100 pessoas aleatórias. Se mais de 50% disserem que a manchete é falsa, podemos descarta-la e classificar como falsa.\n",
    "\n",
    "A previsão de vários modelos de aprendizagem fracos combinados pode resultar em um modelo de aprendizagemforte, que será capaz de distinguir com alta precisão o falso e o verdadeiro.\n",
    "\n",
    "## Com o Ensemble Learning, imitamos esse conceito\n",
    "\n",
    "\n",
    "- **AdaBoost** significa Adaptive Boosting. Ele funciona na técnica de aprendizado de máquina de conjunto sequencial. A ideia geral de impulsionar algoritmos é tentar preditores sequencialmente, onde cada modelo subsequente tenta corrigir os erros de seu predecessor.\n",
    "\n",
    "\n",
    "- **GBM** ou Gradient Boosting também funciona no modelo sequencial. O aumento de gradiente calcula o gradiente (derivado) da função de perda em relação à previsão (em vez dos recursos). O aumento de gradiente aumenta a precisão minimizando a função de perda (erro que é a diferença do valor real e previsto) e tendo essa perda como meta para a próxima iteração.\n",
    "\n",
    "- O algoritmo de aumento de gradiente cria o primeiro aluno fraco e calcula a função de perda. Em seguida, ele cria um segundo aluno para prever a perda após a primeira etapa. A etapa continua para o terceiro aluno e depois para o quarto aluno e assim por diante até que um determinado limite seja alcançado. Portanto, surge a questão de como o AdaBoost é diferente do algoritmo Gradient Boosting, já que ambos funcionam na técnica Boosting.\n",
    "\n",
    "- Tanto o AdaBoost quanto o Gradient Boosting constroem alunos fracos de maneira sequencial. Originalmente, o AdaBoost foi projetado de forma que, a cada passo, a distribuição da amostra fosse adaptada para colocar mais peso nas amostras mal classificadas e menos peso nas amostras classificadas corretamente. A previsão final é uma média ponderada de todos os alunos fracos, onde mais peso é colocado nos alunos mais fortes.\n",
    "\n",
    "- Mais tarde, descobriu-se que o AdaBoost também pode ser expresso em termos de uma estrutura mais geral de modelos aditivos com uma função de perda específica (a perda exponencial).\n",
    "\n",
    "\n",
    "### Portanto, as principais diferenças entre AdaBoost e GBM são as seguintes: \n",
    "\n",
    "- A principal diferença, portanto, é que o Gradient Boosting é um algoritmo genérico para encontrar soluções aproximadas para o problema de modelagem aditiva, enquanto o AdaBoost pode ser visto como um caso especial com uma função de perda específica (função de perda exponencial). Portanto, o aumento de gradiente é muito mais flexível.\n",
    "\n",
    "\n",
    "- O AdaBoost pode ser interpretado de uma perspectiva muito mais intuitiva e pode ser implementado sem a referência a gradientes, reponderando as amostras de treinamento com base nas classificações de alunos anteriores.\n",
    "\n",
    "\n",
    "- No Adaboost, as deficiências são identificadas por pontos de dados de alto peso, enquanto no Gradient Boosting, as deficiências dos alunos fracos existentes são identificadas por gradientes.\n",
    "\n",
    "\n",
    "- Adaboost é mais sobre 'pesos de votação' e aumento de gradiente é mais sobre 'adicionar otimização de gradiente'.\n",
    "\n",
    "\n",
    "- O Adaboost aumenta a precisão dando mais peso ao alvo que é classificado erroneamente pelo modelo. A cada iteração, o algoritmo Adaptive boosting altera a distribuição da amostra modificando os pesos anexados a cada uma das instâncias. Ele aumenta os pesos das instâncias preditas incorretamente e diminui os das instâncias preditas corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d88de",
   "metadata": {},
   "source": [
    "## Classificadores Fracos\n",
    "\n",
    "Um classificador fraco é aquele que produzirá apenas resultados ligeiramente melhores do que jogar uma moeda (imparcial). Em outras palavras, se adivinhando aleatoriamente um rótulo binário estaríamos certos cerca de 50% das vezes, um classificador fraco estaria certo, digamos, 55% (ou qualquer outro número próximo a 50%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47615097",
   "metadata": {},
   "source": [
    "## Classificação das bases de aprendizado (base-learns)\n",
    "\n",
    "- Os aprendizes básicos são classificados em dois tipos.\n",
    "\n",
    "\n",
    "- Com base no arranjo dos aprendizes básicos, os métodos de ensemble podem ser divididos em dois grupos.\n",
    "\n",
    "\n",
    "- Em métodos de ensemble paralelos, os aprendizes básicos são gerados em paralelo, por exemplo - Random Forest.\n",
    "\n",
    "\n",
    "- Nos métodos de conjunto sequencial, os aprendizes básicos são gerados sequencialmente, por exemplo, AdaBoost.\n",
    "\n",
    "\n",
    "- Com base no tipo de aprendizes básicos, os métodos ensemble podem ser divididos em dois grupos.\n",
    "\n",
    "\n",
    "- método de conjunto homogêneo usa o mesmo tipo de aprendiz base em cada iteração.\n",
    "\n",
    "\n",
    "- método de conjunto heterogêneo usa o tipo diferente de aprendiz base em cada iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049515b",
   "metadata": {},
   "source": [
    "### Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06e006c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "\n",
    "# Importar função train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importa classificador AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#importa métricas e modelo para acurácia scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importando classificador obrigatório\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Importando classificador de vetor de suporte\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3995a5",
   "metadata": {},
   "source": [
    "### Importando Conjutno de dados (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ac6506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be53f588",
   "metadata": {},
   "source": [
    "### Pré-visualizando o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "310ba963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b68521",
   "metadata": {},
   "source": [
    "### Visualizando o Súmario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91f32c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdc7af",
   "metadata": {},
   "source": [
    "#### Podemos ver que não há valores nulos no conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaabcce",
   "metadata": {},
   "source": [
    "### Declarando o vetor e a variável linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae22f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06563d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris['species']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d0eef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c863489",
   "metadata": {},
   "source": [
    "### Dividir o conjunto de dados em conjunto de treinamento e conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "004861a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a96cc4",
   "metadata": {},
   "source": [
    "### Construindo o modelo AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b435b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=0)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model1 = abc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6ea2c",
   "metadata": {},
   "source": [
    "### Criando o classificador AdaBoost\n",
    "\n",
    "- Os paramentros mais importantes para a criação de um classificador são: **base_estimator, n_estimator e learning_rate.**\n",
    "\n",
    "####  base_estimator :\n",
    "\n",
    "É o algoritmo de aprendizado a ser usado para treinar os modelos fracos. Isso quase sempre não precisará ser alterado porque, de longe, o aprendizado mais comum para usar com o AdaBoost é uma árvore de decisão - o argumento padrão desse parâmetro.\n",
    "\n",
    "#### n_estimators:\n",
    "É o numero de modelos de treinos interátivos\n",
    "\n",
    "#### learning_rate:\n",
    "\n",
    "É a contribuição de cada modelo para os pesos e o padrão é 1. Reduzir a taxa de aprendizado significa que os pesos serão aumentados ou diminuídos em um pequeno grau, forçando o modelo a treinar mais devagar (mas às vezes resultando em melhores pontuações de desempenho).\n",
    "\n",
    "#### loss:\n",
    "\n",
    "É exclusivo do AdaBoostRegressor e define a função de perda a ser usada ao atualizar os pesos. O padrão é uma função de perda linear, mas pode ser alterada para quadrada ou exponencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5c758",
   "metadata": {},
   "source": [
    "### Avaliando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8095ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Model Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate and print model accuracy\n",
    "print(\"AdaBoost Classifier Model Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd954372",
   "metadata": {},
   "source": [
    "#### Nesse caso, conseguimos 93% de acurácia, o que é considerado uma ótima acurácia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600adc73",
   "metadata": {},
   "source": [
    "### Avaliação adicional com estimativa de base SVC\n",
    "\n",
    "- Para uma avaliação mais aprofundada, usaremos o SVC como um estimador de base da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1397add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with SVC Base Estimator: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "\n",
    "# create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1, random_state=0)\n",
    "\n",
    "\n",
    "# train adaboost classifer\n",
    "model2 = abc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "\n",
    "# calculate and print model accuracy\n",
    "print(\"Model Accuracy with SVC Base Estimator:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1903c1",
   "metadata": {},
   "source": [
    "- Neste caso, obtivemos uma taxa de classificação de 97%, considerada uma precisão muito boa.\n",
    "- Nesse caso, o estimador base SVC está obtendo melhor precisão do que o estimador base da árvore de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7befc6ff",
   "metadata": {},
   "source": [
    "## Vantagens e desvantagens do AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3280ab5",
   "metadata": {},
   "source": [
    "### Vantagens:\n",
    "\n",
    "- AdaBoost é fácil de implementar.\n",
    "\n",
    "- Ele corrige iterativamente os erros do classificador fraco e melhora a precisão combinando alunos fracos.\n",
    "\n",
    "### Desvantagens :\n",
    "\n",
    "- AdaBoost é sensível a dados de ruído.\n",
    "\n",
    "- É altamente afetado por outliers porque tenta ajustar cada ponto perfeitamente.\n",
    "\n",
    "- O AdaBoost é mais lento em comparação com o XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69530cd2",
   "metadata": {},
   "source": [
    "## Resultados e Conclusões\n",
    "\n",
    "- Neste kernel, discutimos o classificador AdaBoost.\n",
    "\n",
    "\n",
    "- Discutimos como os aprendizes-base são classificados.\n",
    "\n",
    "\n",
    "\n",
    "- Em seguida, passamos a discutir a intuição por trás do classificador AdaBoost.\n",
    "\n",
    "\n",
    "\n",
    "- Também discutimos as diferenças entre o classificador AdaBoost e o GBM.\n",
    "\n",
    "\n",
    "- Em seguida, apresentamos a implementação do classificador AdaBoost usando o conjunto de dados iris.\n",
    "\n",
    "\n",
    "\n",
    "- Por fim, discutimos as vantagens e desvantagens do classificador AdaBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e500772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
